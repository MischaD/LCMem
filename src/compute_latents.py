"""
Compute latents for a dataset and, in the same pass, compute channel-wise statistics.
All latents and the statistics are saved, then packaged into a single tarball.
"""

import argparse
import os
import tarfile
import numpy as np
from typing import List, Tuple

import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from tqdm import tqdm

from beyondfid.log import logger
from utils import main_setup
from src.latent import compute_latent_representation, get_latent_model
from src.data import (
    get_distributed_image_dataloader,
    get_data,
)


def setup(rank: int, world_size: int, master_port: int) -> None:
    os.environ["MASTER_ADDR"] = "localhost"
    os.environ["MASTER_PORT"] = str(master_port)
    dist.init_process_group("nccl", rank=rank, world_size=world_size)


def cleanup() -> None:
    if dist.is_initialized():
        dist.destroy_process_group()


def process(
    rank: int,
    world_size: int,
    file_list: List[str],
    model: torch.nn.Module,
    config,
    save_path: str,
    stats_name: str,
) -> None:
    """Worker that computes latents, saves them, and accumulates channel-wise stats.

    Accumulates per-channel sums and squared sums across all pixels to compute mean/std.
    """
    setup(rank, world_size, config.master_port)

    dataloader = get_distributed_image_dataloader(
        file_list,
        rank,
        world_size,
        config,
        base_name=getattr(config, "basedir", None),
    )
    device = torch.device(f"cuda:{rank}")
    model = model.to(device)
    model.eval()

    # Running stats on this rank
    running_sum = None  # float64 [C]
    running_sum_sq = None  # float64 [C]
    running_count = torch.zeros(1, dtype=torch.float64, device=device)

    iterator = tqdm(
        dataloader,
        desc=f"Rank {rank}/{world_size} computing latents",
        bar_format="{l_bar}{bar:30}{r_bar}{bar:-10b}",
        disable=(rank != 0),
    )

    with torch.no_grad():
        for images, _, paths in iterator:
            images = images.to(device, non_blocking=True)
            image_latents = compute_latent_representation(
                images, model, config.compute_latent.batch_size
            )  # [B, C, H, W]

            # Accumulate per-channel stats on latents
            latents = image_latents.to(torch.float32)
            batch_sum = latents.sum(dim=(0, 2, 3)).to(torch.float64)  # [C]
            batch_sum_sq = (latents.square()).sum(dim=(0, 2, 3)).to(torch.float64)  # [C]
            b, _, h, w = latents.shape
            batch_count = torch.tensor([float(b * h * w)], dtype=torch.float64, device=device)

            if running_sum is None:
                running_sum = torch.zeros_like(batch_sum, dtype=torch.float64, device=device)
                running_sum_sq = torch.zeros_like(batch_sum_sq, dtype=torch.float64, device=device)

            running_sum += batch_sum
            running_sum_sq += batch_sum_sq
            running_count += batch_count

            # Save each latent for every image in the batch
            for i, rel_path in enumerate(paths):
                img_save_path = os.path.join(save_path, rel_path + ".pt")
                os.makedirs(os.path.dirname(img_save_path), exist_ok=True)
                torch.save(image_latents[i].cpu(), img_save_path)

    # Distributed reduction to get global sums across ranks
    if running_sum is None:
        # No data on this rank; create zero tensors for reduction
        running_sum = torch.zeros(1, dtype=torch.float64, device=device)
        running_sum_sq = torch.zeros(1, dtype=torch.float64, device=device)

    # Align shapes across ranks for all_reduce
    # Broadcast channel dimension size from rank 0 if needed
    num_channels = torch.tensor([running_sum.numel()], dtype=torch.int64, device=device)
    dist.broadcast(num_channels, src=0)
    if running_sum.numel() != int(num_channels.item()):
        running_sum = torch.zeros(int(num_channels.item()), dtype=torch.float64, device=device)
        running_sum_sq = torch.zeros(int(num_channels.item()), dtype=torch.float64, device=device)

    dist.all_reduce(running_sum, op=dist.ReduceOp.SUM)
    dist.all_reduce(running_sum_sq, op=dist.ReduceOp.SUM)
    dist.all_reduce(running_count, op=dist.ReduceOp.SUM)

    # Only rank 0 computes and saves the statistics
    if rank == 0:
        eps = 1e-12
        mean64 = running_sum / running_count  # [C] float64 on device
        var64 = (running_sum_sq / running_count) - mean64.square()
        var64 = torch.clamp(var64, min=eps)
        mean = mean64.to(torch.float32).cpu()
        std = torch.sqrt(var64).to(torch.float32).cpu()

        torch.save(mean, os.path.join(save_path, f"{stats_name}_channel_mean.pt"))
        torch.save(std, os.path.join(save_path, f"{stats_name}_channel_std.pt"))
        logger.info(f"Saved channel-wise mean/std next to latents for packaging: {os.path.join(save_path, f'{stats_name}_channel_mean.pt')}")

    cleanup()


def apply_norm(
    rank: int,
    world_size: int, 
    file_list,  # may be List[str] (expected) or a CSV path; we handle List[str]
    config,
    save_path: str,
    stats_name: str,
): 
    setup(rank, world_size, config.master_port)

    # Load stats computed in `process`
    mean = torch.load(os.path.join(save_path, f"{stats_name}_channel_mean.pt"))  # [C]
    std = torch.load(os.path.join(save_path, f"{stats_name}_channel_std.pt"))    # [C]
    TARGET_STD = 0.5

    # Prepare affine params as float32 CPU tensors for broadcasting
    mean = mean.to(torch.float32).view(1, -1, 1, 1)
    std = std.to(torch.float32).clamp(min=1e-12)
    scale = (torch.tensor(TARGET_STD, dtype=torch.float32) / std).view(1, -1, 1, 1)  # [1,C,1,1]
    bias = (torch.tensor([0, 0, 0, 0], dtype=torch.float32).view(1, -1, 1, 1) - mean * scale) # [1,C,1,1]

    # Robustly ensure we have a Python list of relative paths
    if isinstance(file_list, str):
        # If a CSV path ever slipped through, fall back to loader
        paths_only, _ = get_data(config)
    else:
        paths_only = file_list

    # Deterministic split across ranks
    total = len(paths_only)
    indices = list(range(total))
    shard = indices[rank::world_size]

    # Rank 0 progress bar
    iterator = shard
    if rank == 0:
        iterator = tqdm(shard, desc=f"Rank {rank}/{world_size} applying norm", bar_format="{l_bar}{bar:30}{r_bar}{bar:-10b}")

    def apply_affine(x: torch.Tensor) -> torch.Tensor:
        """
        x: [C,H,W] or [1,C,H,W] float32/float16/float64
        returns x' with mean 0 and std TARGET_STD per channel
        """
        x_b = x.unsqueeze(0).to(torch.float32)
        x_b = x_b * scale + bias
        return x_b.squeeze(0)

    # Process files for this rank
    skipped = 0
    for idx in iterator:
        rel_path = paths_only[idx]
        latent_path = os.path.join(save_path, rel_path + ".pt")
        if not os.path.exists(latent_path):
            skipped += 1
            continue
        lat = torch.load(latent_path, map_location="cpu")  # expected [C,H,W]
        lat = apply_affine(lat)
        # Overwrite in place
        os.makedirs(os.path.dirname(latent_path), exist_ok=True)
        torch.save(lat, latent_path)

    if rank == 0:
        logger.info(f"Normalization done on rank 0.")

    cleanup()


def create_tarball_from_directory(source_dir: str, tarball_path: str) -> None:
    with tarfile.open(tarball_path, "w:gz") as tar:
        for root, _, files in os.walk(source_dir):
            for f in files:
                full_path = os.path.join(root, f)
                arcname = os.path.relpath(full_path, start=source_dir)
                tar.add(full_path, arcname=arcname)


def run(config) -> None:
    world_size = torch.cuda.device_count()

    # Only allow CSV input
    if not config.filelist.endswith(".csv"):
        raise ValueError("Only CSV files are supported as input. Please provide a .csv file.")
    
    file_list, _ = get_data(config)

    # Output directory for raw .pt latents and stats (to be tarred after)
    latents_output_dir = getattr(config, "output_latents", None)
    if latents_output_dir is None:
        latents_output_dir = os.path.join(os.path.dirname(config.filelist), "Latents")
    os.makedirs(latents_output_dir, exist_ok=True)
    logger.info(f"Saving latents to {latents_output_dir}")

    # Model
    model = get_latent_model(path=config.compute_latent.model_path)

    # Spawn workers
    mp.spawn(
        process,
        args=(
            world_size,
            file_list,
            model,
            config,
            latents_output_dir,
            args.stats_name,
        ),
        nprocs=world_size,
        join=True,
    )

        # Spawn workers
    mp.spawn(
        apply_norm,
        args=(
            world_size,
            file_list,
            config,
            latents_output_dir,
            args.stats_name,
        ),
        nprocs=world_size,
        join=True,
    )

    # Package into a tarball
    logger.info("Creating tarball")
    tarball_name = getattr(config, "tarball_name", None)
    if tarball_name is None:
        base = os.path.basename(os.path.normpath(latents_output_dir))
        tarball_name = base + ".tar.gz"
    tarball_path = os.path.join(os.path.dirname(latents_output_dir), tarball_name)
    create_tarball_from_directory(latents_output_dir, tarball_path)
    logger.info(f"Created tarball: {tarball_path}")

    # Load and output stats for convenience
    mean_path = os.path.join(latents_output_dir, "channel_mean.pt")
    std_path = os.path.join(latents_output_dir, "channel_std.pt")
    if os.path.exists(mean_path):
        mean = torch.load(mean_path)
        logger.info(f"Channel-wise mean: {mean}")
    if os.path.exists(std_path):
        std = torch.load(std_path)
        logger.info(f"Channel-wise std: {std}")


    # Always remove the directory after creating tarball - keep only the tarball
    if args.remove_files: 
        import shutil
        shutil.rmtree(latents_output_dir)
        logger.info(f"Removed directory {latents_output_dir} after packaging. Only tarball remains: {tarball_path}")

    # Post-run instructions: how to extract the tarball
    logger.info(
        "\nTo extract into a new folder:\n"
        f"  mkdir -p output/latents \n"
        f"  tar -xzf {tarball_path} -C output/latents\n\n"
        "To list contents without extracting:\n"
        f"  tar -tzf {tarball_path}\n\n"
        "To extract only the stats files:\n"
        f"  mkdir -p output/latents\n"
        f"  tar -xzf {tarball_path} -C outputs/latents channel_mean.pt channel_std.pt\n"
    )


def get_args():
    parser = argparse.ArgumentParser(description="Compute latents and channel-wise stats, then tar them.")
    parser.add_argument("EXP_PATH", type=str, help="Path to experiment file")
    parser.add_argument("EXP_NAME", type=str, help="Path to Experiment results")
    parser.add_argument("--basedir", type=str, required=True, help="Base directory used to resolve relative paths in the filelist CSV")
    parser.add_argument("--output_latents", type=str, help="Directory where the tarball will be saved. Also tmpdir for single files so high filecount necessary!")
    parser.add_argument("--filelist", type=str, help="CSV file with paths to data")
    parser.add_argument("--tarball_name", type=str, default=None, help="Name for the output tar.gz (default: <output_dir>.tar.gz)")
    parser.add_argument("--stats_name", type=str, default="latents", help="Name for the output stats (default: latents_{mean/std}.pt)")
    parser.add_argument("--batch_size", type=int, default=16, help="Batch size for DataLoader")
    parser.add_argument("--remove_files", action="store_true", help="Remove generated latents after compuating stats (Tarball remains).")
    parser.add_argument("--master_port", type=int, default=12344)
    return parser.parse_args()


if __name__ == "__main__":
    args = get_args()
    config = main_setup(args, name=os.path.basename(__file__).rstrip(".py"))
    config.compute_latent.batch_size = args.batch_size
    # Respect LOCAL_RANK if present
    env_local_rank = int(os.environ.get("LOCAL_RANK", -1))
    if env_local_rank != -1 and getattr(config.dm_training, "local_rank", -1) != env_local_rank:
        config.dm_training.local_rank = env_local_rank
    config.debug = config.EXP_NAME.endswith("debug")
    config.master_port = args.master_port
    run(config)


